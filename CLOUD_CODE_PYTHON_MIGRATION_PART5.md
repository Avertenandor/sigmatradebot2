# üêç –¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï: –ú–∏–≥—Ä–∞—Ü–∏—è SigmaTrade Bot - –ß–ê–°–¢–¨ 5

**–î–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã**  
**–î–∞—Ç–∞:** 2025-11-14  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ö –í–´–ü–û–õ–ù–ï–ù–ò–Æ

---

## ‚ö†Ô∏è –í–ê–ñ–ù–û!

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç **–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã**, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã –≤ PART1-4, –Ω–æ **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´** –¥–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞!

–í—Å–µ –º–æ–¥—É–ª–∏ –∏–∑ —ç—Ç–æ–π —á–∞—Å—Ç–∏ **–ö–†–ò–¢–ò–ß–ù–´** –∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã **–î–û** —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.

---

## üìã –û–ì–õ–ê–í–õ–ï–ù–ò–ï PART5

26. [Multimedia Handlers](#–º–æ–¥—É–ª—å-26-multimedia-handlers)
27. [Request ID Middleware](#–º–æ–¥—É–ª—å-27-request-id-middleware)
28. [Additional Entities](#–º–æ–¥—É–ª—å-28-additional-entities)
29. [Audit Logger (–î–µ—Ç–∞–ª–∏)](#–º–æ–¥—É–ª—å-29-audit-logger-–¥–µ—Ç–∞–ª–∏)
30. [Performance Monitoring (–î–µ—Ç–∞–ª–∏)](#–º–æ–¥—É–ª—å-30-performance-monitoring-–¥–µ—Ç–∞–ª–∏)
31. [RPC Metrics](#–º–æ–¥—É–ª—å-31-rpc-metrics)
32. [Notification Service Extensions](#–º–æ–¥—É–ª—å-32-notification-service-extensions)
33. [Additional Background Jobs](#–º–æ–¥—É–ª—å-33-additional-background-jobs)
34. [Admin Auth Utils](#–º–æ–¥—É–ª—å-34-admin-auth-utils)
35. [Enhanced Validation](#–º–æ–¥—É–ª—å-35-enhanced-validation)

---

## –ú–û–î–£–õ–¨ 26: Multimedia Handlers

### üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–û–±—Ä–∞–±–æ—Ç–∫–∞ –º—É–ª—å—Ç–∏–º–µ–¥–∏–π–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (—Ñ–æ—Ç–æ, –≥–æ–ª–æ—Å, –∞—É–¥–∏–æ, –¥–æ–∫—É–º–µ–Ω—Ç—ã) –¥–ª—è:
- Admin broadcast —Å–∏—Å—Ç–µ–º—ã
- Support —Ç–∏–∫–µ—Ç–æ–≤
- Admin send-to-user

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** üî¥üî¥üî¥ **–ë–ï–ó –≠–¢–û–ì–û –ù–ï –†–ê–ë–û–¢–ê–ï–¢ broadcast –∏ support!**

---

### üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
app/bot/handlers/admin/
‚îú‚îÄ‚îÄ multimedia.py           # NEW! –ú—É–ª—å—Ç–∏–º–µ–¥–∏–∞ handlers
‚îî‚îÄ‚îÄ broadcast_media.py      # NEW! Broadcast –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞

app/bot/handlers/
‚îú‚îÄ‚îÄ support_media.py        # NEW! Support –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞
```

---

### üíª –ö–æ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

#### 26.1 Multimedia Handlers

```python
# app/bot/handlers/admin/multimedia.py

"""
Admin multimedia message handlers.
Handles photo, voice, audio for broadcast and send-to-user.
"""

from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from loguru import logger

from app.bot.states.admin import AdminBroadcastState, AdminSendToUserState
from app.services.user import UserService
from app.services.notification import NotificationService
from app.jobs.queue_manager import get_queue, QueueName
from app.utils.format import escape_markdown

router = Router(name='admin_multimedia')


@router.message(
    AdminBroadcastState.awaiting_message,
    F.photo
)
async def handle_broadcast_photo(
    message: Message,
    state: FSMContext,
    user_service: UserService,
    notification_service: NotificationService,
) -> None:
    """
    Handle photo for broadcast.
    
    Photo is queued for broadcast to all users.
    """
    photo = message.photo[-1]  # Highest resolution
    caption = message.caption or ''
    
    await message.answer('üì® –°—Ç–∞–≤–ª—é —Ä–∞—Å—Å—ã–ª–∫—É —Ñ–æ—Ç–æ –≤ –æ—á–µ—Ä–µ–¥—å...')
    
    # Get all user telegram IDs
    user_ids = await user_service.get_all_telegram_ids()
    
    if not user_ids:
        await message.answer('‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏')
        await state.clear()
        return
    
    # Create broadcast ID for tracking
    broadcast_id = (
        f"broadcast_photo_{message.from_user.id}_{int(message.date.timestamp())}"
    )
    
    # Queue jobs
    queue = get_queue(QueueName.BROADCAST)
    
    jobs_data = []
    for idx, user_id in enumerate(user_ids):
        jobs_data.append({
            'type': 'photo',
            'telegram_id': user_id,
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'file_id': photo.file_id,
            'caption': caption,
            'total_users': len(user_ids),
            'current_index': idx,
        })
    
    await queue.add_bulk(jobs_data)
    
    await message.answer(
        f"‚úÖ –†–∞—Å—Å—ã–ª–∫–∞ —Ñ–æ—Ç–æ –∑–∞–ø—É—â–µ–Ω–∞!\n\n"
        f"üë• –í—Å–µ–≥–æ: {len(user_ids)}\n"
        f"‚è± –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {len(user_ids) // 15} —Å–µ–∫.\n\n"
        f"üìä ID: `{escape_markdown(broadcast_id)}`",
        parse_mode='MarkdownV2'
    )
    
    await state.clear()
    
    logger.info(
        "Broadcast photo queued",
        extra={
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'total_users': len(user_ids),
        }
    )


@router.message(
    AdminBroadcastState.awaiting_message,
    F.voice
)
async def handle_broadcast_voice(
    message: Message,
    state: FSMContext,
    user_service: UserService,
) -> None:
    """
    Handle voice message for broadcast.
    
    Voice is queued for broadcast to all users.
    """
    voice = message.voice
    caption = message.caption or ''
    
    await message.answer('üì® –°—Ç–∞–≤–ª—é —Ä–∞—Å—Å—ã–ª–∫—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥—å...')
    
    user_ids = await user_service.get_all_telegram_ids()
    
    if not user_ids:
        await message.answer('‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏')
        await state.clear()
        return
    
    broadcast_id = (
        f"broadcast_voice_{message.from_user.id}_{int(message.date.timestamp())}"
    )
    
    queue = get_queue(QueueName.BROADCAST)
    
    jobs_data = []
    for idx, user_id in enumerate(user_ids):
        jobs_data.append({
            'type': 'voice',
            'telegram_id': user_id,
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'file_id': voice.file_id,
            'caption': caption,
            'total_users': len(user_ids),
            'current_index': idx,
        })
    
    await queue.add_bulk(jobs_data)
    
    await message.answer(
        f"‚úÖ –†–∞—Å—Å—ã–ª–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω–∞!\n\n"
        f"üë• –í—Å–µ–≥–æ: {len(user_ids)}\n"
        f"‚è± –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {len(user_ids) // 15} —Å–µ–∫.\n\n"
        f"üìä ID: `{escape_markdown(broadcast_id)}`",
        parse_mode='MarkdownV2'
    )
    
    await state.clear()
    
    logger.info(
        "Broadcast voice queued",
        extra={
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'total_users': len(user_ids),
        }
    )


@router.message(
    AdminBroadcastState.awaiting_message,
    F.audio
)
async def handle_broadcast_audio(
    message: Message,
    state: FSMContext,
    user_service: UserService,
) -> None:
    """
    Handle audio message for broadcast.
    
    Audio is queued for broadcast to all users.
    """
    audio = message.audio
    caption = message.caption or ''
    
    await message.answer('üì® –°—Ç–∞–≤–ª—é —Ä–∞—Å—Å—ã–ª–∫—É –∞—É–¥–∏–æ –≤ –æ—á–µ—Ä–µ–¥—å...')
    
    user_ids = await user_service.get_all_telegram_ids()
    
    if not user_ids:
        await message.answer('‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏')
        await state.clear()
        return
    
    broadcast_id = (
        f"broadcast_audio_{message.from_user.id}_{int(message.date.timestamp())}"
    )
    
    queue = get_queue(QueueName.BROADCAST)
    
    jobs_data = []
    for idx, user_id in enumerate(user_ids):
        jobs_data.append({
            'type': 'audio',
            'telegram_id': user_id,
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'file_id': audio.file_id,
            'caption': caption,
            'total_users': len(user_ids),
            'current_index': idx,
        })
    
    await queue.add_bulk(jobs_data)
    
    await message.answer(
        f"‚úÖ –†–∞—Å—Å—ã–ª–∫–∞ –∞—É–¥–∏–æ –∑–∞–ø—É—â–µ–Ω–∞!\n\n"
        f"üë• –í—Å–µ–≥–æ: {len(user_ids)}\n"
        f"‚è± –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {len(user_ids) // 15} —Å–µ–∫.\n\n"
        f"üìä ID: `{escape_markdown(broadcast_id)}`",
        parse_mode='MarkdownV2'
    )
    
    await state.clear()
    
    logger.info(
        "Broadcast audio queued",
        extra={
            'admin_id': message.from_user.id,
            'broadcast_id': broadcast_id,
            'total_users': len(user_ids),
        }
    )
```

---

#### 26.2 Support Media Handlers

```python
# app/bot/handlers/support_media.py

"""
Support ticket multimedia handlers.
Allows users to attach photos and documents to support tickets.
"""

from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from loguru import logger

from app.bot.states.support import SupportState
from app.schemas.support import SupportTicketCreate

router = Router(name='support_media')


@router.message(
    SupportState.awaiting_input,
    F.photo
)
async def handle_support_photo(
    message: Message,
    state: FSMContext,
) -> None:
    """
    Handle photo attachment for support ticket.
    
    Photo is saved to state data for ticket creation.
    """
    photo = message.photo[-1]
    caption = message.caption or ''
    
    # Get current state data
    data = await state.get_data()
    
    # Add photo to attachments
    attachments = data.get('attachments', [])
    attachments.append({
        'type': 'photo',
        'file_id': photo.file_id,
        'caption': caption,
    })
    
    await state.update_data(attachments=attachments)
    
    await message.answer(
        "üì∏ –§–æ—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ –æ–±—Ä–∞—â–µ–Ω–∏—é.\n\n"
        "–ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë —Ñ–∞–π–ª—ã –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã."
    )
    
    logger.info(
        "Photo added to support ticket",
        extra={
            'user_id': message.from_user.id,
            'attachments_count': len(attachments),
        }
    )


@router.message(
    SupportState.awaiting_input,
    F.document
)
async def handle_support_document(
    message: Message,
    state: FSMContext,
) -> None:
    """
    Handle document attachment for support ticket.
    
    Document is saved to state data for ticket creation.
    """
    document = message.document
    caption = message.caption or ''
    
    # Get current state data
    data = await state.get_data()
    
    # Add document to attachments
    attachments = data.get('attachments', [])
    attachments.append({
        'type': 'document',
        'file_id': document.file_id,
        'file_name': document.file_name,
        'caption': caption,
    })
    
    await state.update_data(attachments=attachments)
    
    await message.answer(
        f"üìé –î–æ–∫—É–º–µ–Ω—Ç '{document.file_name}' –¥–æ–±–∞–≤–ª–µ–Ω –∫ –æ–±—Ä–∞—â–µ–Ω–∏—é.\n\n"
        "–ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë —Ñ–∞–π–ª—ã –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã."
    )
    
    logger.info(
        "Document added to support ticket",
        extra={
            'user_id': message.from_user.id,
            'file_name': document.file_name,
            'attachments_count': len(attachments),
        }
    )
```

---

### ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ú–û–î–£–õ–¨ 26

- [ ] –°–æ–∑–¥–∞—Ç—å `app/bot/handlers/admin/multimedia.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `handle_broadcast_photo()`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `handle_broadcast_voice()`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `handle_broadcast_audio()`
- [ ] –°–æ–∑–¥–∞—Ç—å `app/bot/handlers/support_media.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `handle_support_photo()`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `handle_support_document()`
- [ ] –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–æ—É—Ç–µ—Ä—ã –≤ `bot/__init__.py`
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å broadcast —Ñ–æ—Ç–æ/–≥–æ–ª–æ—Å/–∞—É–¥–∏–æ
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å support attachments

---

## –ú–û–î–£–õ–¨ 27: Request ID Middleware

### üéØ –û–ø–∏—Å–∞–Ω–∏–µ

**–ö–†–ò–¢–ò–ß–ù–û!** –ü–µ—Ä–≤—ã–π middleware –≤ —Ü–µ–ø–æ—á–∫–µ –¥–ª—è end-to-end request tracking.

**–ó–∞—á–µ–º:**
- –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
- Debugging –∏ troubleshooting
- Distributed tracing
- Correlation logs

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** üî¥üî¥üî¥ **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–µ—Ä–≤—ã–º –≤ middleware chain!**

---

### üíª –ö–æ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

```python
# app/bot/middlewares/request_id.py

"""
Request ID Middleware.

CRITICAL: MUST be first middleware in chain for end-to-end request tracking.

Adds unique request ID to every update for:
- Debugging
- Troubleshooting
- Distributed tracing
- Log correlation
"""

import uuid
from typing import Callable, Dict, Any, Awaitable

from aiogram import BaseMiddleware
from aiogram.types import Update, TelegramObject
from loguru import logger


class RequestIdMiddleware(BaseMiddleware):
    """
    Adds unique request ID to every update.
    
    IMPORTANT: This middleware MUST be registered FIRST
    before all other middlewares for proper request tracking.
    
    Usage:
        dp.update.middleware(RequestIdMiddleware())
    """
    
    async def __call__(
        self,
        handler: Callable[[TelegramObject, Dict[str, Any]], Awaitable[Any]],
        event: Update,
        data: Dict[str, Any],
    ) -> Any:
        """
        Add request ID to update data and logger context.
        
        Args:
            handler: Next handler in chain
            event: Telegram update
            data: Handler data dict
            
        Returns:
            Handler result
        """
        # Generate unique request ID
        request_id = str(uuid.uuid4())
        
        # Add to data dict (available in all handlers)
        data['request_id'] = request_id
        
        # Extract user info for logging
        user_id = None
        update_type = event.update_type if hasattr(event, 'update_type') else 'unknown'
        
        if event.message:
            user_id = event.message.from_user.id if event.message.from_user else None
        elif event.callback_query:
            user_id = event.callback_query.from_user.id
        elif event.inline_query:
            user_id = event.inline_query.from_user.id
        
        # Log request start with context
        logger.bind(
            request_id=request_id,
            user_id=user_id,
            update_type=update_type,
        ).debug("Request started")
        
        try:
            # Call next handler with contextualized logger
            with logger.contextualize(
                request_id=request_id,
                user_id=user_id,
            ):
                result = await handler(event, data)
            
            # Log request completion
            logger.bind(
                request_id=request_id,
            ).debug("Request completed")
            
            return result
            
        except Exception as e:
            # Log request failure
            logger.bind(
                request_id=request_id,
            ).error(
                f"Request failed: {str(e)}",
                exc_info=True
            )
            raise
```

---

### üîß –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è

```python
# app/bot/__init__.py

from aiogram import Dispatcher
from app.bot.middlewares.request_id import RequestIdMiddleware
from app.bot.middlewares.logger import LoggerMiddleware
from app.bot.middlewares.auth import AuthMiddleware
# ... other middlewares

def register_middlewares(dp: Dispatcher) -> None:
    """
    Register all middlewares.
    
    CRITICAL ORDER:
    1. RequestIdMiddleware - MUST BE FIRST!
    2. LoggerMiddleware
    3. RateLimitMiddleware
    4. AuthMiddleware
    5. ... other middlewares
    """
    # IMPORTANT: RequestIdMiddleware MUST be first!
    dp.update.middleware(RequestIdMiddleware())
    
    # Other middlewares
    dp.update.middleware(LoggerMiddleware())
    dp.update.middleware(RateLimitMiddleware())
    dp.update.middleware(AuthMiddleware())
    # ...
```

---

### ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ú–û–î–£–õ–¨ 27

- [ ] –°–æ–∑–¥–∞—Ç—å `app/bot/middlewares/request_id.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `RequestIdMiddleware`
- [ ] –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å **–ü–ï–†–í–´–ú** –≤ middleware chain
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å logger contextualization
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ request_id –¥–æ—Å—Ç—É–ø–µ–Ω –≤–æ –≤—Å–µ—Ö handlers
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ª–æ–≥–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç request_id

---

## –ú–û–î–£–õ–¨ 28: Additional Entities

### üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–î–≤–∞ **–ö–†–ò–¢–ò–ß–ù–´–•** entity, –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –≤ PART1:
1. `PaymentRetry` - –¥–ª—è retry –ª–æ–≥–∏–∫–∏ –ø–ª–∞—Ç–µ–∂–µ–π
2. `FailedNotification` - –¥–ª—è retry —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** üî¥üî¥üî¥ **–ë–ï–ó –≠–¢–û–ì–û –ù–ï –†–ê–ë–û–¢–ê–ï–¢ retry —Å–∏—Å—Ç–µ–º–∞!**

---

### üíª –ö–æ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

#### 28.1 PaymentRetry Entity

```python
# app/models/payment_retry.py

"""
Payment Retry Model.

Tracks failed payment attempts for retry with exponential backoff.
Part of Dead Letter Queue (DLQ) system.
"""

from datetime import datetime
from decimal import Decimal
from sqlalchemy import (
    Column, Integer, String, Numeric, DateTime,
    ForeignKey, Text, Boolean, Enum as SQLEnum
)
from sqlalchemy.orm import relationship

from app.database.base import Base
from app.utils.constants import TransactionType


class PaymentRetry(Base):
    """
    Payment retry tracking.
    
    Stores failed payment attempts with metadata for retry logic.
    Used by payment-retry.job for automatic retries.
    """
    
    __tablename__ = 'payment_retries'
    
    id = Column(Integer, primary_key=True, index=True)
    
    # Related withdrawal or transaction
    withdrawal_id = Column(
        Integer,
        ForeignKey('withdrawals.id', ondelete='CASCADE'),
        nullable=True,
        index=True
    )
    transaction_id = Column(
        Integer,
        ForeignKey('transactions.id', ondelete='CASCADE'),
        nullable=True,
        index=True
    )
    
    # Payment details
    recipient_address = Column(String(42), nullable=False)
    amount = Column(Numeric(20, 8), nullable=False)
    transaction_type = Column(
        SQLEnum(TransactionType),
        nullable=False,
        index=True
    )
    
    # Retry tracking
    attempts = Column(Integer, default=0, nullable=False)
    max_attempts = Column(Integer, default=5, nullable=False)
    next_retry_at = Column(DateTime, nullable=False, index=True)
    last_error = Column(Text, nullable=True)
    
    # Status
    is_completed = Column(Boolean, default=False, nullable=False, index=True)
    completed_at = Column(DateTime, nullable=True)
    tx_hash = Column(String(66), nullable=True)  # If finally succeeded
    
    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(
        DateTime,
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
        nullable=False
    )
    
    # Relationships
    withdrawal = relationship("Withdrawal", back_populates="payment_retries")
    transaction = relationship("Transaction", back_populates="payment_retries")
    
    def __repr__(self) -> str:
        return (
            f"<PaymentRetry(id={self.id}, "
            f"recipient={self.recipient_address[:10]}..., "
            f"amount={self.amount}, "
            f"attempts={self.attempts}/{self.max_attempts})>"
        )
    
    @property
    def can_retry(self) -> bool:
        """Check if can retry."""
        return (
            not self.is_completed
            and self.attempts < self.max_attempts
            and datetime.utcnow() >= self.next_retry_at
        )
```

---

#### 28.2 FailedNotification Entity

```python
# app/models/failed_notification.py

"""
Failed Notification Model.

Tracks failed notification attempts for retry.
Part of notification retry system.
"""

from datetime import datetime
from sqlalchemy import (
    Column, Integer, BigInteger, String, DateTime,
    ForeignKey, Text, Boolean, JSON
)
from sqlalchemy.orm import relationship

from app.database.base import Base


class FailedNotification(Base):
    """
    Failed notification tracking.
    
    Stores failed notification attempts with metadata for retry logic.
    Used by notification-retry.job for automatic retries.
    """
    
    __tablename__ = 'failed_notifications'
    
    id = Column(Integer, primary_key=True, index=True)
    
    # Target user
    user_id = Column(
        Integer,
        ForeignKey('users.id', ondelete='CASCADE'),
        nullable=False,
        index=True
    )
    telegram_id = Column(BigInteger, nullable=False, index=True)
    
    # Notification details
    notification_type = Column(String(50), nullable=False, index=True)
    message_text = Column(Text, nullable=False)
    message_data = Column(JSON, nullable=True)  # Additional data (buttons, etc.)
    
    # Retry tracking
    attempts = Column(Integer, default=0, nullable=False)
    max_attempts = Column(Integer, default=3, nullable=False)
    next_retry_at = Column(DateTime, nullable=False, index=True)
    last_error = Column(Text, nullable=True)
    
    # Status
    is_sent = Column(Boolean, default=False, nullable=False, index=True)
    sent_at = Column(DateTime, nullable=True)
    
    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(
        DateTime,
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
        nullable=False
    )
    
    # Relationships
    user = relationship("User", back_populates="failed_notifications")
    
    def __repr__(self) -> str:
        return (
            f"<FailedNotification(id={self.id}, "
            f"user_id={self.user_id}, "
            f"type={self.notification_type}, "
            f"attempts={self.attempts}/{self.max_attempts})>"
        )
    
    @property
    def can_retry(self) -> bool:
        """Check if can retry."""
        return (
            not self.is_sent
            and self.attempts < self.max_attempts
            and datetime.utcnow() >= self.next_retry_at
        )
```

---

### üìù Migration

```python
# alembic/versions/xxx_add_retry_entities.py

"""Add PaymentRetry and FailedNotification entities

Revision ID: xxx
Revises: yyy
Create Date: 2025-01-xx
"""

from alembic import op
import sqlalchemy as sa

def upgrade():
    # Create payment_retries table
    op.create_table(
        'payment_retries',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('withdrawal_id', sa.Integer(), nullable=True),
        sa.Column('transaction_id', sa.Integer(), nullable=True),
        sa.Column('recipient_address', sa.String(42), nullable=False),
        sa.Column('amount', sa.Numeric(20, 8), nullable=False),
        sa.Column('transaction_type', sa.String(50), nullable=False),
        sa.Column('attempts', sa.Integer(), default=0, nullable=False),
        sa.Column('max_attempts', sa.Integer(), default=5, nullable=False),
        sa.Column('next_retry_at', sa.DateTime(), nullable=False),
        sa.Column('last_error', sa.Text(), nullable=True),
        sa.Column('is_completed', sa.Boolean(), default=False, nullable=False),
        sa.Column('completed_at', sa.DateTime(), nullable=True),
        sa.Column('tx_hash', sa.String(66), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(['withdrawal_id'], ['withdrawals.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['transaction_id'], ['transactions.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_payment_retries_withdrawal_id', 'payment_retries', ['withdrawal_id'])
    op.create_index('ix_payment_retries_next_retry_at', 'payment_retries', ['next_retry_at'])
    op.create_index('ix_payment_retries_is_completed', 'payment_retries', ['is_completed'])
    
    # Create failed_notifications table
    op.create_table(
        'failed_notifications',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('telegram_id', sa.BigInteger(), nullable=False),
        sa.Column('notification_type', sa.String(50), nullable=False),
        sa.Column('message_text', sa.Text(), nullable=False),
        sa.Column('message_data', sa.JSON(), nullable=True),
        sa.Column('attempts', sa.Integer(), default=0, nullable=False),
        sa.Column('max_attempts', sa.Integer(), default=3, nullable=False),
        sa.Column('next_retry_at', sa.DateTime(), nullable=False),
        sa.Column('last_error', sa.Text(), nullable=True),
        sa.Column('is_sent', sa.Boolean(), default=False, nullable=False),
        sa.Column('sent_at', sa.DateTime(), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_failed_notifications_user_id', 'failed_notifications', ['user_id'])
    op.create_index('ix_failed_notifications_next_retry_at', 'failed_notifications', ['next_retry_at'])
    op.create_index('ix_failed_notifications_is_sent', 'failed_notifications', ['is_sent'])

def downgrade():
    op.drop_table('failed_notifications')
    op.drop_table('payment_retries')
```

---

### ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ú–û–î–£–õ–¨ 28

- [ ] –°–æ–∑–¥–∞—Ç—å `app/models/payment_retry.py`
- [ ] –°–æ–∑–¥–∞—Ç—å `app/models/failed_notification.py`
- [ ] –°–æ–∑–¥–∞—Ç—å Alembic migration
- [ ] –î–æ–±–∞–≤–∏—Ç—å relationships –≤ User/Withdrawal/Transaction
- [ ] –°–æ–∑–¥–∞—Ç—å repositories –¥–ª—è –æ–±–æ–∏—Ö entities
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å can_retry –ª–æ–≥–∏–∫—É

---

## –ú–û–î–£–õ–¨ 29: Audit Logger (–î–µ—Ç–∞–ª–∏)

### üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è audit logging —Å–∏—Å—Ç–µ–º—ã –¥–ª—è compliance –∏ security.

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** üî¥üî¥ **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è security audit**

---

### üíª –ö–æ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

```python
# app/utils/audit_logger.py

"""
Audit Logger.

CRITICAL for compliance and security audit.

Logs all user and admin actions to:
- Database (UserAction entity)
- Structured logs
- (Optional) External audit system
"""

from typing import Optional, Dict, Any
from datetime import datetime

from loguru import logger
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.user_action import UserAction
from app.utils.constants import UserActionType, AdminActionType


async def log_user_action(
    db: AsyncSession,
    user_id: int,
    action_type: UserActionType,
    metadata: Optional[Dict[str, Any]] = None,
    ip_address: Optional[str] = None,
    user_agent: Optional[str] = None,
) -> UserAction:
    """
    Log user action to database and structured logs.
    
    CRITICAL for:
    - Compliance tracking
    - Security audit
    - Debugging
    - User activity analysis
    
    Args:
        db: Database session
        user_id: User ID
        action_type: Type of action
        metadata: Additional action data
        ip_address: User IP address (if available)
        user_agent: User agent string (if available)
        
    Returns:
        Created UserAction record
    """
    # Create database record
    action = UserAction(
        user_id=user_id,
        action_type=action_type.value,
        metadata=metadata or {},
        ip_address=ip_address,
        user_agent=user_agent,
        timestamp=datetime.utcnow(),
    )
    
    db.add(action)
    await db.commit()
    await db.refresh(action)
    
    # Log to structured logs
    logger.info(
        "User action",
        extra={
            'user_id': user_id,
            'action_type': action_type.value,
            'action_id': action.id,
            'metadata': metadata,
            'ip_address': ip_address,
        }
    )
    
    return action


async def log_admin_action(
    db: AsyncSession,
    admin_id: int,
    action_type: AdminActionType,
    target_user_id: Optional[int] = None,
    metadata: Optional[Dict[str, Any]] = None,
    ip_address: Optional[str] = None,
) -> UserAction:
    """
    Log admin action.
    
    CRITICAL for security audit of privileged operations.
    
    Args:
        db: Database session
        admin_id: Admin user ID
        action_type: Type of admin action
        target_user_id: Target user ID (if applicable)
        metadata: Additional action data
        ip_address: Admin IP address (if available)
        
    Returns:
        Created UserAction record
    """
    # Enhance metadata with admin-specific data
    admin_metadata = metadata or {}
    admin_metadata['is_admin_action'] = True
    admin_metadata['admin_id'] = admin_id
    
    if target_user_id:
        admin_metadata['target_user_id'] = target_user_id
    
    # Create database record
    action = UserAction(
        user_id=admin_id,  # Admin is also a user
        action_type=action_type.value,
        metadata=admin_metadata,
        ip_address=ip_address,
        timestamp=datetime.utcnow(),
    )
    
    db.add(action)
    await db.commit()
    await db.refresh(action)
    
    # Log to structured logs with higher priority
    logger.warning(  # Use warning level for admin actions
        "Admin action",
        extra={
            'admin_id': admin_id,
            'action_type': action_type.value,
            'action_id': action.id,
            'target_user_id': target_user_id,
            'metadata': admin_metadata,
            'ip_address': ip_address,
        }
    )
    
    return action


# Convenience functions for common actions

async def log_registration(
    db: AsyncSession,
    user_id: int,
    referrer_id: Optional[int] = None,
) -> UserAction:
    """Log user registration."""
    return await log_user_action(
        db=db,
        user_id=user_id,
        action_type=UserActionType.REGISTRATION_COMPLETED,
        metadata={'referrer_id': referrer_id} if referrer_id else {},
    )


async def log_deposit(
    db: AsyncSession,
    user_id: int,
    deposit_id: int,
    amount: float,
    level: int,
) -> UserAction:
    """Log deposit confirmation."""
    return await log_user_action(
        db=db,
        user_id=user_id,
        action_type=UserActionType.DEPOSIT_CONFIRMED,
        metadata={
            'deposit_id': deposit_id,
            'amount': amount,
            'level': level,
        },
    )


async def log_withdrawal(
    db: AsyncSession,
    user_id: int,
    withdrawal_id: int,
    amount: float,
) -> UserAction:
    """Log withdrawal request."""
    return await log_user_action(
        db=db,
        user_id=user_id,
        action_type=UserActionType.WITHDRAWAL_REQUESTED,
        metadata={
            'withdrawal_id': withdrawal_id,
            'amount': amount,
        },
    )


async def log_admin_ban(
    db: AsyncSession,
    admin_id: int,
    target_user_id: int,
    reason: str,
) -> UserAction:
    """Log admin banning user."""
    return await log_admin_action(
        db=db,
        admin_id=admin_id,
        action_type=AdminActionType.USER_BANNED,
        target_user_id=target_user_id,
        metadata={'reason': reason},
    )


async def log_admin_broadcast(
    db: AsyncSession,
    admin_id: int,
    broadcast_id: str,
    total_users: int,
) -> UserAction:
    """Log admin broadcast."""
    return await log_admin_action(
        db=db,
        admin_id=admin_id,
        action_type=AdminActionType.BROADCAST_SENT,
        metadata={
            'broadcast_id': broadcast_id,
            'total_users': total_users,
        },
    )
```

---

### ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ú–û–î–£–õ–¨ 29

- [ ] –°–æ–∑–¥–∞—Ç—å `app/utils/audit_logger.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `log_user_action()`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `log_admin_action()`
- [ ] –î–æ–±–∞–≤–∏—Ç—å convenience functions
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ handlers
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –ª–æ–≥–∏—Ä—É—é—Ç—Å—è

---

## –ú–û–î–£–õ–¨ 30: Performance Monitoring (–î–µ—Ç–∞–ª–∏)

### üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è performance monitoring –¥–ª—è production.

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** üî¥üî¥ **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è production**

---

### üíª –ö–æ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

```python
# app/utils/performance_monitor.py

"""
Performance Monitoring.

CRITICAL for production operations.

Monitors:
- CPU usage
- Memory usage
- Disk I/O
- Network I/O
- Active connections
- Event loop lag
"""

import asyncio
import psutil
from typing import Optional
from datetime import datetime

from loguru import logger


class PerformanceMonitor:
    """
    Performance monitoring service.
    
    Reports system metrics periodically for:
    - Production monitoring
    - Performance optimization
    - Resource planning
    - Alerting
    """
    
    def __init__(self):
        self._reporting_task: Optional[asyncio.Task] = None
        self._memory_task: Optional[asyncio.Task] = None
        self._process = psutil.Process()
        
    async def start_performance_reporting(
        self,
        interval_seconds: int = 3600  # Every hour
    ) -> None:
        """
        Start performance reporting.
        
        Reports comprehensive performance stats every hour.
        
        Args:
            interval_seconds: Reporting interval in seconds
        """
        self._reporting_task = asyncio.create_task(
            self._performance_reporting_loop(interval_seconds)
        )
        logger.info(
            "Performance reporting started",
            extra={'interval_seconds': interval_seconds}
        )
    
    async def stop_performance_reporting(self) -> None:
        """Stop performance reporting."""
        if self._reporting_task:
            self._reporting_task.cancel()
            try:
                await self._reporting_task
            except asyncio.CancelledError:
                pass
            logger.info("Performance reporting stopped")
    
    async def start_memory_monitoring(
        self,
        interval_seconds: int = 300,  # Every 5 minutes
        warning_threshold: float = 80.0  # 80%
    ) -> None:
        """
        Start memory monitoring.
        
        Logs memory usage every 5 minutes.
        Warnings if usage exceeds threshold.
        
        Args:
            interval_seconds: Check interval in seconds
            warning_threshold: Warning threshold percentage
        """
        self._memory_task = asyncio.create_task(
            self._memory_monitoring_loop(interval_seconds, warning_threshold)
        )
        logger.info(
            "Memory monitoring started",
            extra={
                'interval_seconds': interval_seconds,
                'warning_threshold': warning_threshold,
            }
        )
    
    async def stop_memory_monitoring(self) -> None:
        """Stop memory monitoring."""
        if self._memory_task:
            self._memory_task.cancel()
            try:
                await self._memory_task
            except asyncio.CancelledError:
                pass
            logger.info("Memory monitoring stopped")
    
    async def _performance_reporting_loop(
        self,
        interval_seconds: int
    ) -> None:
        """Performance reporting loop."""
        while True:
            try:
                await asyncio.sleep(interval_seconds)
                await self._report_performance()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Performance reporting error: {e}")
    
    async def _memory_monitoring_loop(
        self,
        interval_seconds: int,
        warning_threshold: float
    ) -> None:
        """Memory monitoring loop."""
        while True:
            try:
                await asyncio.sleep(interval_seconds)
                await self._check_memory(warning_threshold)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Memory monitoring error: {e}")
    
    async def _report_performance(self) -> None:
        """
        Report comprehensive performance stats.
        
        Metrics:
        - CPU usage (system and process)
        - Memory usage (system and process)
        - Disk I/O
        - Network I/O
        - Thread/task counts
        - Event loop lag
        """
        # CPU metrics
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        process_cpu = self._process.cpu_percent()
        
        # Memory metrics
        memory = psutil.virtual_memory()
        process_memory = self._process.memory_info()
        
        # Disk metrics
        disk = psutil.disk_usage('/')
        disk_io = psutil.disk_io_counters()
        
        # Network metrics
        net_io = psutil.net_io_counters()
        
        # Process metrics
        num_threads = self._process.num_threads()
        
        # Event loop lag (measure task scheduling delay)
        start = asyncio.get_event_loop().time()
        await asyncio.sleep(0)
        lag_ms = (asyncio.get_event_loop().time() - start) * 1000
        
        # Log comprehensive stats
        logger.info(
            "Performance stats",
            extra={
                # CPU
                'cpu_percent': cpu_percent,
                'cpu_count': cpu_count,
                'process_cpu_percent': process_cpu,
                
                # Memory
                'memory_total_gb': memory.total / (1024**3),
                'memory_available_gb': memory.available / (1024**3),
                'memory_percent': memory.percent,
                'process_memory_rss_mb': process_memory.rss / (1024**2),
                'process_memory_vms_mb': process_memory.vms / (1024**2),
                
                # Disk
                'disk_total_gb': disk.total / (1024**3),
                'disk_free_gb': disk.free / (1024**3),
                'disk_percent': disk.percent,
                'disk_read_mb': disk_io.read_bytes / (1024**2) if disk_io else 0,
                'disk_write_mb': disk_io.write_bytes / (1024**2) if disk_io else 0,
                
                # Network
                'net_sent_mb': net_io.bytes_sent / (1024**2),
                'net_recv_mb': net_io.bytes_recv / (1024**2),
                
                # Process
                'num_threads': num_threads,
                'event_loop_lag_ms': lag_ms,
                
                # Timestamp
                'timestamp': datetime.utcnow().isoformat(),
            }
        )
    
    async def _check_memory(self, warning_threshold: float) -> None:
        """
        Check memory usage and warn if high.
        
        Args:
            warning_threshold: Warning threshold percentage
        """
        memory = psutil.virtual_memory()
        process_memory = self._process.memory_info()
        
        if memory.percent > warning_threshold:
            logger.warning(
                "High memory usage detected",
                extra={
                    'memory_percent': memory.percent,
                    'memory_available_gb': memory.available / (1024**3),
                    'process_memory_rss_mb': process_memory.rss / (1024**2),
                    'warning_threshold': warning_threshold,
                }
            )
        else:
            logger.debug(
                "Memory check OK",
                extra={
                    'memory_percent': memory.percent,
                    'memory_available_gb': memory.available / (1024**3),
                }
            )


# Global instance
performance_monitor = PerformanceMonitor()


# Convenience functions
async def start_performance_reporting(interval_seconds: int = 3600) -> None:
    """Start performance reporting."""
    await performance_monitor.start_performance_reporting(interval_seconds)


async def stop_performance_reporting() -> None:
    """Stop performance reporting."""
    await performance_monitor.stop_performance_reporting()


async def start_memory_monitoring(
    interval_seconds: int = 300,
    warning_threshold: float = 80.0
) -> None:
    """Start memory monitoring."""
    await performance_monitor.start_memory_monitoring(
        interval_seconds,
        warning_threshold
    )


async def stop_memory_monitoring() -> None:
    """Stop memory monitoring."""
    await performance_monitor.stop_memory_monitoring()
```

---

### üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ main.py

```python
# app/main.py

from app.utils.performance_monitor import (
    start_performance_reporting,
    stop_performance_reporting,
    start_memory_monitoring,
    stop_memory_monitoring,
)

async def startup():
    """Application startup."""
    # ... other startup tasks
    
    # Start performance monitoring
    logger.info("Starting performance monitoring...")
    await start_performance_reporting()  # Every hour
    await start_memory_monitoring()  # Every 5 minutes
    logger.info("‚úÖ Performance monitoring started")


async def shutdown():
    """Application shutdown."""
    # Stop performance monitoring
    logger.info("Stopping performance monitoring...")
    await stop_performance_reporting()
    await stop_memory_monitoring()
    logger.info("‚úÖ Performance monitoring stopped")
    
    # ... other shutdown tasks
```

---

### ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ú–û–î–£–õ–¨ 30

- [ ] –°–æ–∑–¥–∞—Ç—å `app/utils/performance_monitor.py`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `PerformanceMonitor` class
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `main.py` startup/shutdown
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å intervals (3600s, 300s)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å warning thresholds
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å unit —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ production-like environment

---

## –ú–û–î–£–õ–¨ 31-35: –ö—Ä–∞—Ç–∫–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è

–ò–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞, –º–æ–¥—É–ª–∏ 31-35 –æ–ø–∏—Å–∞–Ω—ã –∫—Ä–∞—Ç–∫–æ. –ü–æ–ª–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É.

---

### –ú–û–î–£–õ–¨ 31: RPC Metrics
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ RPC –≤—ã–∑–æ–≤–æ–≤
- Prometheus metrics
- Latency tracking
- Error rate tracking

### –ú–û–î–£–õ–¨ 32: Notification Service Extensions
- `send_photo_message()`
- `send_voice_message()`
- `send_audio_message()`
- `send_document_message()`

### –ú–û–î–£–õ–¨ 33: Additional Background Jobs
- `notification-retry.job`
- `payment-retry.job`
- `disk-guard.job`

### –ú–û–î–£–õ–¨ 34: Admin Auth Utils
- `generate_master_key()`
- `validate_master_key()`
- `hash_master_key()`
- `create_admin_session()`

### –ú–û–î–£–õ–¨ 35: Enhanced Validation
- `validate_ethereum_address()` with checksum
- `validate_deposit_amount()` with level limits
- `validate_withdrawal_amount()` with balance check
- `validate_financial_password()` with complexity rules
- `sanitize_user_input()` for injection protection

---

## ‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ô –ß–ï–ö–õ–ò–°–¢ PART5

- [ ] –ú–û–î–£–õ–¨ 26: Multimedia Handlers
- [ ] –ú–û–î–£–õ–¨ 27: Request ID Middleware
- [ ] –ú–û–î–£–õ–¨ 28: Additional Entities
- [ ] –ú–û–î–£–õ–¨ 29: Audit Logger (–î–µ—Ç–∞–ª–∏)
- [ ] –ú–û–î–£–õ–¨ 30: Performance Monitoring (–î–µ—Ç–∞–ª–∏)
- [ ] –ú–û–î–£–õ–¨ 31: RPC Metrics
- [ ] –ú–û–î–£–õ–¨ 32: Notification Service Extensions
- [ ] –ú–û–î–£–õ–¨ 33: Additional Background Jobs
- [ ] –ú–û–î–£–õ–¨ 34: Admin Auth Utils
- [ ] –ú–û–î–£–õ–¨ 35: Enhanced Validation

---

## üìä –û–ë–ù–û–í–õ–Å–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê

–ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è PART5:

```
–í—Å–µ–≥–æ –º–æ–¥—É–ª–µ–π:         35 (–±—ã–ª–æ 25)
–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤:          260+ (–±—ã–ª–æ 225+)
–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞:      62,000+ (–±—ã–ª–æ 53,700+)
Entities:              21 (–±—ã–ª–æ 19)
Jobs:                  9 (–±—ã–ª–æ 6)
Handlers:              95+ (–±—ã–ª–æ 40+)
Middlewares:           8 (–±—ã–ª–æ 5)
Services:              14+ (–±—ã–ª–æ 10)
Utils:                 25+ (–±—ã–ª–æ 20+)

–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏:        45-55 —á–∞—Å–æ–≤ (–±—ã–ª–æ 35-45)
```

---

## üö® –ö–†–ò–¢–ò–ß–ù–û!

**–í–°–ï –º–æ–¥—É–ª–∏ –∏–∑ PART5 –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´!**

–ë–µ–∑ –Ω–∏—Ö –±–æ—Ç **–ù–ï –ë–£–î–ï–¢ –ü–û–õ–ù–û–°–¢–¨–Æ –§–£–ù–ö–¶–ò–û–ù–ê–õ–ï–ù**!

---

**–°–æ–∑–¥–∞–Ω–æ**: 2025-11-14  
**–°—Ç–∞—Ç—É—Å**: ‚úÖ –ì–û–¢–û–í–û –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: üî¥üî¥üî¥ –ö–†–ò–¢–ò–ß–ù–´–ô

